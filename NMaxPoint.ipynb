{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "keras.__version__\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers, layers, models, regularizers, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('TrackTrainingSetArSc.csv',delimiter=' ', skip_header=1)\n",
    "print((\"Rozmiar zestawu treningowego = %d x %d \")%(data.shape[0], data.shape[1]))\n",
    "datapd = pd.read_csv('TrackTrainingSetArSc.csv', sep=' ', header=0)\n",
    "datapd = datapd.drop(['qOverPXZ'], axis=1)\n",
    "datapd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jednostki = {'p': ' [GeV]', \n",
    "             'px': ' [GeV]', \n",
    "             'py': ' [GeV]', \n",
    "             'pz': ' [GeV]',\n",
    "             'enDep': ' [GeV]',\n",
    "             'pFirstX': ' [cm]',\n",
    "             'pFirstY': ' [cm]',\n",
    "             'pFirstZ': ' [cm]',\n",
    "             'pLastX': ' [cm]',\n",
    "             'pLastY': ' [cm]',\n",
    "             'pLastZ': ' [cm]',\n",
    "             'pFirstBx': ' [T]',\n",
    "             'pFirstBy': ' [T]',\n",
    "             'pFirstBz': ' [T]',\n",
    "             'pLastBx': ' [T]',\n",
    "             'pLastBy': ' [T]',\n",
    "             'pLastBz': ' [T]',\n",
    "             'q': '', \n",
    "             'Ndedx': '',\n",
    "             'qOverPXZ': '',\n",
    "             'nMaxPoint': ''}\n",
    "print(datapd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsize = 20\n",
    "i=1\n",
    "fig = plt.figure(figsize=(25,25))\n",
    "for key in datapd.keys():\n",
    "    plt.subplot(8,3,i)\n",
    "    i+=1\n",
    "    plt.hist(datapd[key], bins=40)\n",
    "    plt.xlabel(str(key) + jednostki[key], fontsize=fsize*1.1) #fontsize zeby zwiekszyc etykiete\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(size=fsize)\n",
    "    plt.yticks(size=fsize)\n",
    "    plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig('RozkladCech.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "fig = plt.figure(figsize=(14,12))\n",
    "for key in datapd.drop(\"nMaxPoint\", axis=1).keys():\n",
    "    plt.subplot(5,4,i)\n",
    "    i+=1\n",
    "    plt.hist2d(x=datapd[key], y=datapd['nMaxPoint'], bins=50, cmap='jet', norm=LogNorm())\n",
    "    plt.xlabel(str(key) + jednostki[key], fontsize=fsize*0.6)\n",
    "    plt.ylabel('nMaxPoint', fontsize=fsize*0.6)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(size=fsize*0.5)\n",
    "    plt.yticks(size=fsize*0.5)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "fig.savefig('ZaleznosciNMaxPointsOdCech.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array(datapd.drop(['nMaxPoint'], axis=1)), np.array(datapd['nMaxPoint'])\n",
    "\n",
    "X = X[:,3:19] \n",
    "\n",
    "y_lin = y.astype('float32')\n",
    "y_log = to_categorical(y, num_classes = 241)\n",
    "\n",
    "\n",
    "train, test, train_label_lin, test_label_lin = train_test_split(X, y_lin, shuffle=True, test_size=0.25)\n",
    "train, test, train_label_log, test_label_log = train_test_split(X, y_log, shuffle=True, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(X, axis = 0)\n",
    "std = np.std(X, axis = 0)\n",
    "\n",
    "\n",
    "train_normalized = (train - mean)/std\n",
    "test_normalized = (test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                                                  factor=0.1, \n",
    "                                                  patience=15, \n",
    "                                                  verbose=1, \n",
    "                                                  mode='auto', \n",
    "                                                  min_delta=0.01, \n",
    "                                                  cooldown=0, \n",
    "                                                  min_lr=0)\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                           min_delta=0.001, \n",
    "                                           patience=20, \n",
    "                                           verbose=1, \n",
    "                                           mode='auto', \n",
    "                                           baseline=None, \n",
    "                                           restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = 0.1\n",
    "model_lin = models.Sequential()\n",
    "model_lin.add(layers.Dense(256, activation='relu', input_shape=(train.shape[1], ), kernel_initializer='random_normal'))\n",
    "model_lin.add(layers.Dropout(drop))\n",
    "model_lin.add(layers.Dense(256, activation='relu'))\n",
    "model_lin.add(layers.Dropout(drop))\n",
    "model_lin.add(layers.Dense(256, activation='relu'))\n",
    "model_lin.add(layers.Dense(256, activation='relu'))\n",
    "model_lin.add(layers.Dropout(drop))\n",
    "model_lin.add(layers.Dense(256, activation='relu'))\n",
    "model_lin.add(layers.Dense(256, activation='relu'))\n",
    "model_lin.add(layers.Dense(256, activation='relu'))\n",
    "model_lin.add(layers.Dense(256, activation='relu'))\n",
    "model_lin.add(layers.Dense(1))\n",
    "\n",
    "model_lin.compile(loss=losses.mean_squared_error, \n",
    "               optimizer=optimizers.Adam(),\n",
    "               metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lin.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lin = model_lin.fit(train_normalized, \n",
    "                      train_label_lin, \n",
    "                      epochs=200, \n",
    "                      validation_split=0.2, \n",
    "                      batch_size=64, \n",
    "                      callbacks=[learning_rate, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = 0.1\n",
    "model_log = models.Sequential()\n",
    "model_log.add(layers.Dense(256, activation='relu', input_shape=(train.shape[1], ), kernel_initializer='random_normal'))\n",
    "model_log.add(layers.Dropout(drop))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dropout(drop))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dense(256, activation='relu'))\n",
    "model_log.add(layers.Dense(241, activation=(tf.nn.softmax)))\n",
    "\n",
    "model_log.compile(loss=losses.categorical_crossentropy, \n",
    "               optimizer=optimizers.Adam(lr=1e-3), \n",
    "               metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_log = model_log.fit(train_normalized, \n",
    "                      train_label_log, \n",
    "                      epochs=200, \n",
    "                      validation_split=0.2, \n",
    "                      batch_size=64, \n",
    "                      callbacks=[learning_rate, early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_log = model_log.predict(test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history_lin.history['mean_absolute_error'])\n",
    "plt.plot(history_lin.history['val_mean_absolute_error'])\n",
    "plt.title(\"Średni błąd bezwzględny modelu liniowego\")\n",
    "plt.ylabel(\"Średni błąd bezwzględny\")\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.legend(['Zbiór treningowy', 'Zbiór walidacyjny'], loc='upper left')\n",
    "plt.show()\n",
    "# fig.savefig('mae-lin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history_lin.history['loss'])\n",
    "plt.plot(history_lin.history['val_loss'])\n",
    "plt.title(\"Funkcja straty modelu liniowego\")\n",
    "plt.ylabel(\"Wartość straty\")\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.legend(['Zbiór treningowy', 'Zbiór walidacyjny'], loc='upper left')\n",
    "plt.show()\n",
    "# fig.savefig('loss-lin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history_log.history['categorical_accuracy'])\n",
    "plt.plot(history_log.history['val_categorical_accuracy'])\n",
    "plt.title(\"Skuteczność predykcji modelu logistycznego\")\n",
    "plt.ylabel(\"Skuteczność\")\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.legend(['Zbiór treningowy', 'Zbiór walidacyjny'], loc='upper left')\n",
    "plt.show()\n",
    "# fig.savefig('accuracy-log.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history_log.history['loss'])\n",
    "plt.plot(history_log.history['val_loss'])\n",
    "plt.title(\"Funkcja straty modelu logistycznego\")\n",
    "plt.ylabel(\"Wartość straty\")\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.legend(['Zbiór treningowy', 'Zbiór walidacyjny'], loc='upper left')\n",
    "plt.show()\n",
    "# fig.savefig('loss-log.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lin = model_lin.evaluate(test_normalized, test_label_lin)\n",
    "print(('Średni błąd bezwzględny wynosi wynosi: %2.2f')%(results_lin[1]))\n",
    "print(('Przewidywany NMaxPoint średnio odbiega od wartości docelowych właśnie o: %2.2f punkta')%(results_lin[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_log = model_log.evaluate(test_normalized, test_label_log)\n",
    "print(('Dokladnosc zbioru testowego wynosi wynosi: %2.2f%s')%(results_log[1]*100, '%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lin = model_lin.predict(test_normalized)\n",
    "prediction_log = model_log.predict(test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_label_lin\n",
    "y_lin = np.round(prediction_lin).astype('int64')\n",
    "y_lin = y_lin.reshape(y_lin.shape[0])\n",
    "z_lin = x - y_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_label_log.argmax(axis=1)\n",
    "y_log = prediction_log.argmax(axis=1)\n",
    "z_log = x - y_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W sytuacji idealnej spodziewamy się zestawu punktów układających się w linię prostą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "hist, xbins, ybins, im = plt.hist2d(x=x, y=y_lin, bins=100, cmap='jet', norm = LogNorm())\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('N oszacowany')\n",
    "plt.show()\n",
    "# fig.savefig('Macierz korelacji - lin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "hist, xbins, ybins, im = plt.hist2d(x=x, y=y_log, bins=100, cmap='jet', norm = LogNorm())\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('N oszacowany')\n",
    "plt.show()\n",
    "# fig.savefig('Macierz korelacji - log.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W sytuacji idealnej spodziewamy się jednego słupka na pozycji zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "y_lin, x, patches = plt.hist(z_lin, bins = 100)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('N - N oszacowany')\n",
    "plt.grid()\n",
    "plt.axvline(5, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(-5, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "# fig.savefig('Rzeczywisteaoszacowane-lin.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "y_log, x, patches = plt.hist(z_log, bins = 100)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('N - N oszacowany')\n",
    "plt.grid()\n",
    "plt.axvline(5, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.axvline(-5, color='k', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n",
    "# fig.savefig('Rzeczywisteaoszacowane-log.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
